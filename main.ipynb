{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:13:22.728650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 17:13:23.112250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:23.112266: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 17:13:24.397594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:24.397676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:24.397684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional, BatchNormalization, GRU, TimeDistributed\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow import convert_to_tensor, concat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando arquivos de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wavs/sample-631.wav</td>\n",
       "      <td>Depois que foi atropelado, só atravessa na fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wavs/sample-2757.wav</td>\n",
       "      <td>A cidade também tem uma instituição de ensino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wavs/sample-5578.wav</td>\n",
       "      <td>Também os astronautas depressa se juntaram às...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wavs/sample-3712.wav</td>\n",
       "      <td>Nessa idade, começou a praticar balé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wavs/sample-3434.wav</td>\n",
       "      <td>Um exemplo de conhecimento de terceiro tipo é...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wav_filename                                         transcript\n",
       "0   wavs/sample-631.wav  Depois que foi atropelado, só atravessa na fai...\n",
       "1  wavs/sample-2757.wav  A cidade também tem uma instituição de ensino ...\n",
       "2  wavs/sample-5578.wav   Também os astronautas depressa se juntaram às...\n",
       "3  wavs/sample-3712.wav              Nessa idade, começou a praticar balé.\n",
       "4  wavs/sample-3434.wav   Um exemplo de conhecimento de terceiro tipo é..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\n",
    "    \"./TTS-Portuguese-Corpus_22khz/train_TTS-Portuguese_Corpus_metadata.csv\", \n",
    "    sep = \"|\",\n",
    "    index_col = False\n",
    ")\n",
    "\n",
    "train = train[['wav_filename','transcript']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wavs/sample-5672.wav</td>\n",
       "      <td>A juventude tinha que revolucionar a escola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wavs/sample-5655.wav</td>\n",
       "      <td>A inauguração da vila é quarta ou quinta-feira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wavs/sample-5656.wav</td>\n",
       "      <td>Vote se você tiver o título de eleitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wavs/sample-5755.wav</td>\n",
       "      <td>A inauguração da vila é quarta ou quinta-feira.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wavs/sample-5659.wav</td>\n",
       "      <td>Em muitas cidades a população está diminuindo.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wav_filename                                       transcript\n",
       "0  wavs/sample-5672.wav      A juventude tinha que revolucionar a escola\n",
       "1  wavs/sample-5655.wav   A inauguração da vila é quarta ou quinta-feira\n",
       "2  wavs/sample-5656.wav           Vote se você tiver o título de eleitor\n",
       "3  wavs/sample-5755.wav  A inauguração da vila é quarta ou quinta-feira.\n",
       "4  wavs/sample-5659.wav   Em muitas cidades a população está diminuindo."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./TTS-Portuguese-Corpus_22khz/test_TTS-Portuguese_Corpus_metadata.csv\", sep = \"|\",\n",
    "    index_col = False)\n",
    "\n",
    "test = test[['wav_filename','transcript']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando librosa para converter arquivos de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://librosa.org/doc/latest/generated/librosa.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./all_waves_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./all_waves_df.pkl'):\n",
    "    all_waves_df = pd.read_pickle('./all_waves_df.pkl')\n",
    "else:\n",
    "    dir_path = './TTS-Portuguese-Corpus_22khz/'\n",
    "    wav_paths = train['wav_filename']\n",
    "    all_waves = []\n",
    "\n",
    "    for index, wav_path in enumerate(wav_paths):\n",
    "        samples, sample_rate = librosa.load(dir_path + wav_path)\n",
    "        samples = librosa.resample(samples, orig_sr=sample_rate, target_sr = 8000)   \n",
    "        all_waves.append((samples, train.loc[index,'transcript']))\n",
    "    \n",
    "    all_waves_df = pd.DataFrame(all_waves, columns = ['tensor', 'transcript'])\n",
    "    all_waves_df.to_pickle('./all_waves_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tensor</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0002558262, 0.007106832, 0.015172318, 0.01...</td>\n",
       "      <td>Depois que foi atropelado, só atravessa na fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0007501879, -5.3689382e-05, -0.0017680669, ...</td>\n",
       "      <td>A cidade também tem uma instituição de ensino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.018647028, 0.036927525, 0.04546329, 0.04682...</td>\n",
       "      <td>Também os astronautas depressa se juntaram às...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.001063928, 0.0019695, 0.0022690534, 0.00247...</td>\n",
       "      <td>Nessa idade, começou a praticar balé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0063640825, 0.00304457, -0.010580226, -0.02...</td>\n",
       "      <td>Um exemplo de conhecimento de terceiro tipo é...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tensor  \\\n",
       "0  [-0.0002558262, 0.007106832, 0.015172318, 0.01...   \n",
       "1  [0.0007501879, -5.3689382e-05, -0.0017680669, ...   \n",
       "2  [0.018647028, 0.036927525, 0.04546329, 0.04682...   \n",
       "3  [0.001063928, 0.0019695, 0.0022690534, 0.00247...   \n",
       "4  [0.0063640825, 0.00304457, -0.010580226, -0.02...   \n",
       "\n",
       "                                          transcript  \n",
       "0  Depois que foi atropelado, só atravessa na fai...  \n",
       "1  A cidade também tem uma instituição de ensino ...  \n",
       "2   Também os astronautas depressa se juntaram às...  \n",
       "3              Nessa idade, começou a praticar balé.  \n",
       "4   Um exemplo de conhecimento de terceiro tipo é...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_waves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_df['tensor_len'] = all_waves_df['tensor'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tensor_size = all_waves_df['tensor_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_df['tensor_with_padding'] = all_waves_df['tensor'].map(lambda x: librosa.util.fix_length(x,size=max_tensor_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitetura da rede neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape arrays 2D para 3D pois o input para camada Conv1D deve ser um array 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves = np.array(all_waves).reshape(-1, len(all_waves), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteca para brincar com os hiperparâmetros da rede neural: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criei um dicionário para facilitar a utilização dos hiperparâmetros da rede neural, mas ele usa tantos que talvez seja melhor separá-los de outra forma. Ainda estou estudando cada parâmetro para entender melhor o que ele fez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'momentum': 0.99,\n",
    "    'epsilon': 1e-3,\n",
    "    'strides': 1,\n",
    "    'max_pooling': 3,\n",
    "    'dropout': 0.3,\n",
    "    'gru_batch_size': 128,\n",
    "    'padding': 'valid',\n",
    "    'activation_relu': 'relu',\n",
    "    'activation_softmax': 'softmax',\n",
    "    'merge_mode': 'sum',\n",
    "    'center': True,\n",
    "    'scale': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_architecture(len_wave_array, label_array):\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    inputs = Input(shape = (len_wave_array, 1))\n",
    "\n",
    "    # First Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(inputs)\n",
    "\n",
    "    # First Conv1D layer\n",
    "    x = Conv1D(\n",
    "        8, 13, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Second Conv1D layer\n",
    "    x = Conv1D(\n",
    "        16, 11, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Third Conv1D layer\n",
    "    x = Conv1D(\n",
    "        32, 9, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Second Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(x)\n",
    "\n",
    "    # Bidirectional GRUs\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = True), merge_mode = hyperparams['merge_mode'])(x)\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = True), merge_mode = hyperparams['merge_mode'])(x)\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = False), merge_mode = hyperparams['merge_mode'])(x)\n",
    "\n",
    "   # Third Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(x)\n",
    "\n",
    "    # Dense Layer 1\n",
    "    x = Dense(256, activation = hyperparams['activation_relu'])(x)\n",
    "    outputs = Dense(len(label_array), activation = hyperparams['activation_softmax'])(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 1, \n",
    "    patience = 10, \n",
    "    min_delta = 0.0001\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'speech2text_model.hdf5', \n",
    "    monitor = 'val_acc', \n",
    "    verbose = 1, \n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de perda foi definida como \"entropia cruzada categórica\" pois se tratava de um problema de multi-classificação.\n",
    "Esse link fala sobre funções de perda, mas ainda preciso dar uma estudada melhor no assunto: https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células abaixo ele chama x_train, y_train e x_valid, y_valid.\n",
    "Entendi que x_valid, y_valid é o que costumamos chamar de x_test, y_test.\n",
    "Mas ele já disponibilizou os datasets divididos em treino e teste, então não soube direito o que colocar nessas quatro variáveis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula abaixo resulta em erro porque não há elementos em len_8000_waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_8000_x_train, len_8000_x_valid, len_8000_y_train, len_8000_y_valid = train_test_split(\n",
    "#     np.array(len_8000_waves),\n",
    "#     np.array(len_8000_y),\n",
    "#     # stratify = y, -> comentado porque nossas \"classes\" têm apenas 1 elemento cada, e para stratify precisa de pelo menos 2\n",
    "#     test_size = 0.2,\n",
    "#     random_state = 777,\n",
    "#     shuffle = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula abaixo estava demorando demais para rodar, então comentei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = len_8000_model.fit(\n",
    "#     x = np.asarray(len_8000_x_train).astype('float32'), \n",
    "#     y = np.asarray(len_8000_y_train).astype('float32'),\n",
    "#     epochs = 100, \n",
    "#     callbacks = [early_stop, checkpoint], \n",
    "#     batch_size = 32, \n",
    "#     validation_data = (len_8000_x_valid, len_8000_y_valid)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerando todas as ondas\n",
    "Mesma lógica da seção acima, mas trocando tudo que tem \"len_8000_\" para \"all_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_waves_df['transcript'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3024,)\n"
     ]
    }
   ],
   "source": [
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:44:43.693154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-06 16:44:43.693173: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-06 16:44:43.693188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (claudio-vostro5490): /proc/driver/nvidia/version does not exist\n",
      "2022-12-06 16:44:43.693546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 361440, 1)]       0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 361440, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 361428, 8)         112       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 120476, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120476, 8)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 120466, 16)        1424      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 40155, 16)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 40155, 16)         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 40147, 32)         4640      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 13382, 32)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13382, 32)         0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13382, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 13382, 128)       124416    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 13382, 128)       198144    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              198144    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3024)              777168    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,337,716\n",
      "Trainable params: 1,337,394\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7feef9a252e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_waves_model = nn_architecture(max_tensor_size, all_labels)\n",
    "all_waves_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_model.compile(loss = 'categorical_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_label_enconder = LabelEncoder()\n",
    "all_waves_y = all_waves_label_enconder.fit_transform(all_labels)\n",
    "\n",
    "all_waves_classes = list(all_waves_label_enconder.classes_)\n",
    "all_waves_y = np_utils.to_categorical(all_waves_y, num_classes = len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_x_train, all_waves_x_test, all_waves_y_train, all_waves_y_test = train_test_split(\n",
    "    np.array(all_waves_df['tensor_with_padding'].values),\n",
    "    np.array(all_waves_y),\n",
    "    test_size = 0.2,\n",
    "    random_state = 777,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixou rodou por 15min e não printou nada..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "for i in all_waves_x_train:\n",
    "    l.append(convert_to_tensor(i.reshape(1,len(i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:44:59.568750: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 400475520 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.664753: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 401921280 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.760527: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 403367040 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.862497: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 404812800 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.956855: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 406258560 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "t = l[0]\n",
    "for i in l[1:]:\n",
    "    t = Concatenate(axis=0)([t,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2419, 3024)\n",
      "(2419, 361440)\n"
     ]
    }
   ],
   "source": [
    "print(all_waves_y_train.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/76 [..............................] - ETA: 5:14:13 - loss: 8.0126 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "hist = all_waves_model.fit(\n",
    "    x = t, \n",
    "    y = np.asarray(all_waves_y_train).astype('float32'),\n",
    "    epochs = 100, \n",
    "    callbacks = [early_stop, checkpoint], \n",
    "    batch_size = 32, \n",
    "    validation_data = (all_waves_x_test, all_waves_y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label = 'train')\n",
    "plt.plot(hist.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
