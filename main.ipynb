{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:13:22.728650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 17:13:23.112250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:23.112266: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 17:13:24.397594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:24.397676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 17:13:24.397684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional, BatchNormalization, GRU, TimeDistributed\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor, concat\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando arquivos de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wavs/sample-631.wav</td>\n",
       "      <td>Depois que foi atropelado, só atravessa na fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wavs/sample-2757.wav</td>\n",
       "      <td>A cidade também tem uma instituição de ensino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wavs/sample-5578.wav</td>\n",
       "      <td>Também os astronautas depressa se juntaram às...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wavs/sample-3712.wav</td>\n",
       "      <td>Nessa idade, começou a praticar balé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wavs/sample-3434.wav</td>\n",
       "      <td>Um exemplo de conhecimento de terceiro tipo é...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wav_filename                                         transcript\n",
       "0   wavs/sample-631.wav  Depois que foi atropelado, só atravessa na fai...\n",
       "1  wavs/sample-2757.wav  A cidade também tem uma instituição de ensino ...\n",
       "2  wavs/sample-5578.wav   Também os astronautas depressa se juntaram às...\n",
       "3  wavs/sample-3712.wav              Nessa idade, começou a praticar balé.\n",
       "4  wavs/sample-3434.wav   Um exemplo de conhecimento de terceiro tipo é..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\n",
    "    \"./TTS-Portuguese-Corpus_22khz/train_TTS-Portuguese_Corpus_metadata.csv\", \n",
    "    sep = \"|\",\n",
    "    index_col = False\n",
    ")\n",
    "\n",
    "train = train[['wav_filename','transcript']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wavs/sample-5672.wav</td>\n",
       "      <td>A juventude tinha que revolucionar a escola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wavs/sample-5655.wav</td>\n",
       "      <td>A inauguração da vila é quarta ou quinta-feira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wavs/sample-5656.wav</td>\n",
       "      <td>Vote se você tiver o título de eleitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wavs/sample-5755.wav</td>\n",
       "      <td>A inauguração da vila é quarta ou quinta-feira.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wavs/sample-5659.wav</td>\n",
       "      <td>Em muitas cidades a população está diminuindo.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wav_filename                                       transcript\n",
       "0  wavs/sample-5672.wav      A juventude tinha que revolucionar a escola\n",
       "1  wavs/sample-5655.wav   A inauguração da vila é quarta ou quinta-feira\n",
       "2  wavs/sample-5656.wav           Vote se você tiver o título de eleitor\n",
       "3  wavs/sample-5755.wav  A inauguração da vila é quarta ou quinta-feira.\n",
       "4  wavs/sample-5659.wav   Em muitas cidades a população está diminuindo."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./TTS-Portuguese-Corpus_22khz/test_TTS-Portuguese_Corpus_metadata.csv\", sep = \"|\",\n",
    "    index_col = False)\n",
    "\n",
    "test = test[['wav_filename','transcript']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando librosa para converter arquivos de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://librosa.org/doc/latest/generated/librosa.load.html"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('./all_waves_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "os.path.exists('./all_waves_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [05:29<00:00,  9.19it/s]\n"
     ]
    }
   ],
   "source": [
=======
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
    "if os.path.exists('./all_waves_df.pkl'):\n",
    "    all_waves_df = pd.read_pickle('./all_waves_df.pkl')\n",
    "else:\n",
    "    dir_path = './TTS-Portuguese-Corpus_22khz/'\n",
    "    wav_paths = train['wav_filename']\n",
    "    all_waves = []\n",
    "\n",
<<<<<<< HEAD
    "    for index, wav_path in tqdm(enumerate(wav_paths), total=len(wav_paths)):\n",
=======
    "    for index, wav_path in enumerate(wav_paths):\n",
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
    "        samples, sample_rate = librosa.load(dir_path + wav_path)\n",
    "        samples = librosa.resample(samples, orig_sr=sample_rate, target_sr = 8000)   \n",
    "        all_waves.append((samples, train.loc[index,'transcript']))\n",
    "    \n",
    "    all_waves_df = pd.DataFrame(all_waves, columns = ['tensor', 'transcript'])\n",
    "    all_waves_df.to_pickle('./all_waves_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tensor</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0002558262, 0.007106832, 0.015172318, 0.01...</td>\n",
       "      <td>Depois que foi atropelado, só atravessa na fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0007501879, -5.3689382e-05, -0.0017680669, ...</td>\n",
       "      <td>A cidade também tem uma instituição de ensino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.018647028, 0.036927525, 0.04546329, 0.04682...</td>\n",
       "      <td>Também os astronautas depressa se juntaram às...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.001063928, 0.0019695, 0.0022690534, 0.00247...</td>\n",
       "      <td>Nessa idade, começou a praticar balé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0063640825, 0.00304457, -0.010580226, -0.02...</td>\n",
       "      <td>Um exemplo de conhecimento de terceiro tipo é...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tensor  \\\n",
       "0  [-0.0002558262, 0.007106832, 0.015172318, 0.01...   \n",
       "1  [0.0007501879, -5.3689382e-05, -0.0017680669, ...   \n",
       "2  [0.018647028, 0.036927525, 0.04546329, 0.04682...   \n",
       "3  [0.001063928, 0.0019695, 0.0022690534, 0.00247...   \n",
       "4  [0.0063640825, 0.00304457, -0.010580226, -0.02...   \n",
       "\n",
       "                                          transcript  \n",
       "0  Depois que foi atropelado, só atravessa na fai...  \n",
       "1  A cidade também tem uma instituição de ensino ...  \n",
       "2   Também os astronautas depressa se juntaram às...  \n",
       "3              Nessa idade, começou a praticar balé.  \n",
       "4   Um exemplo de conhecimento de terceiro tipo é...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_waves_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_df = all_waves_df.iloc[:int((all_waves_df.size)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_df['tensor_len'] = all_waves_df['tensor'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tensor_size = all_waves_df['tensor_len'].max()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_df['tensor_with_padding'] = all_waves_df['tensor'].map(lambda x: librosa.util.fix_length(x,size=max_tensor_size))"
   ]
  },
  {
=======
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitetura da rede neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape arrays 2D para 3D pois o input para camada Conv1D deve ser um array 3D."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 9,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves = np.array(all_waves).reshape(-1, len(all_waves), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteca para brincar com os hiperparâmetros da rede neural: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criei um dicionário para facilitar a utilização dos hiperparâmetros da rede neural, mas ele usa tantos que talvez seja melhor separá-los de outra forma. Ainda estou estudando cada parâmetro para entender melhor o que ele fez."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 10,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'momentum': 0.99,\n",
    "    'epsilon': 1e-3,\n",
    "    'strides': 1,\n",
    "    'max_pooling': 3,\n",
    "    'dropout': 0.3,\n",
    "    'gru_batch_size': 128,\n",
    "    'padding': 'valid',\n",
    "    'activation_relu': 'relu',\n",
    "    'activation_softmax': 'softmax',\n",
    "    'merge_mode': 'sum',\n",
    "    'center': True,\n",
    "    'scale': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 11,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_architecture(len_wave_array, label_array):\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    inputs = Input(shape = (len_wave_array, 1))\n",
    "\n",
    "    # First Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(inputs)\n",
    "\n",
    "    # First Conv1D layer\n",
    "    x = Conv1D(\n",
    "        8, 13, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Second Conv1D layer\n",
    "    x = Conv1D(\n",
    "        16, 11, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Third Conv1D layer\n",
    "    x = Conv1D(\n",
    "        32, 9, \n",
    "        padding = hyperparams['padding'], \n",
    "        activation = hyperparams['activation_relu'], \n",
    "        strides = hyperparams['strides']\n",
    "    )(x)\n",
    "    x = MaxPooling1D(hyperparams['max_pooling'])(x)\n",
    "    x = Dropout(hyperparams['dropout'])(x)\n",
    "\n",
    "    # Second Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(x)\n",
    "\n",
    "    # Bidirectional GRUs\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = True), merge_mode = hyperparams['merge_mode'])(x)\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = True), merge_mode = hyperparams['merge_mode'])(x)\n",
    "    x = Bidirectional(GRU(hyperparams['gru_batch_size'], return_sequences = False), merge_mode = hyperparams['merge_mode'])(x)\n",
    "\n",
    "   # Third Batch Normalization layer\n",
    "    x = BatchNormalization(\n",
    "        axis = -1, \n",
    "        momentum = hyperparams['momentum'], \n",
    "        epsilon = hyperparams['epsilon'], \n",
    "        center = hyperparams['center'], \n",
    "        scale = hyperparams['scale'] \n",
    "    )(x)\n",
    "\n",
    "    # Dense Layer 1\n",
    "    x = Dense(256, activation = hyperparams['activation_relu'])(x)\n",
    "    outputs = Dense(len(label_array), activation = hyperparams['activation_softmax'])(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 12,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    verbose = 1, \n",
    "    patience = 10, \n",
    "    min_delta = 0.0001\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'speech2text_model.hdf5', \n",
    "    monitor = 'val_acc', \n",
    "    verbose = 1, \n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de perda foi definida como \"entropia cruzada categórica\" pois se tratava de um problema de multi-classificação.\n",
    "Esse link fala sobre funções de perda, mas ainda preciso dar uma estudada melhor no assunto: https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células abaixo ele chama x_train, y_train e x_valid, y_valid.\n",
    "Entendi que x_valid, y_valid é o que costumamos chamar de x_test, y_test.\n",
    "Mas ele já disponibilizou os datasets divididos em treino e teste, então não soube direito o que colocar nessas quatro variáveis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula abaixo resulta em erro porque não há elementos em len_8000_waves."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 13,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_8000_x_train, len_8000_x_valid, len_8000_y_train, len_8000_y_valid = train_test_split(\n",
    "#     np.array(len_8000_waves),\n",
    "#     np.array(len_8000_y),\n",
    "#     # stratify = y, -> comentado porque nossas \"classes\" têm apenas 1 elemento cada, e para stratify precisa de pelo menos 2\n",
    "#     test_size = 0.2,\n",
    "#     random_state = 777,\n",
    "#     shuffle = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula abaixo estava demorando demais para rodar, então comentei."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 14,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = len_8000_model.fit(\n",
    "#     x = np.asarray(len_8000_x_train).astype('float32'), \n",
    "#     y = np.asarray(len_8000_y_train).astype('float32'),\n",
    "#     epochs = 100, \n",
    "#     callbacks = [early_stop, checkpoint], \n",
    "#     batch_size = 32, \n",
    "#     validation_data = (len_8000_x_valid, len_8000_y_valid)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerando todas as ondas\n",
    "Mesma lógica da seção acima, mas trocando tudo que tem \"len_8000_\" para \"all_\"."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 15,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_waves_df['transcript'].values"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 16,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483,)\n"
     ]
    }
   ],
   "source": [
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 17,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:44:43.693154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-06 16:44:43.693173: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-06 16:44:43.693188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (claudio-vostro5490): /proc/driver/nvidia/version does not exist\n",
      "2022-12-06 16:44:43.693546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 264721, 1)]       0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 264721, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 264709, 8)         112       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 88236, 8)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 88236, 8)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 88226, 16)         1424      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 29408, 16)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 29408, 16)         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 29400, 32)         4640      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 9800, 32)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 9800, 32)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9800, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 9800, 128)        124416    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 9800, 128)        198144    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              198144    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 483)               124131    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 684,679\n",
      "Trainable params: 684,357\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<keras.engine.functional.Functional at 0x14e1fa957c0>"
      ]
     },
     "execution_count": 45,
=======
       "<keras.engine.functional.Functional at 0x7feef9a252e0>"
      ]
     },
     "execution_count": 17,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_waves_model = nn_architecture(max_tensor_size, all_labels)\n",
    "all_waves_model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 18,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_model.compile(loss = 'categorical_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 19,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_label_enconder = LabelEncoder()\n",
    "all_waves_y = all_waves_label_enconder.fit_transform(all_labels)\n",
    "\n",
    "all_waves_classes = list(all_waves_label_enconder.classes_)\n",
    "all_waves_y = np_utils.to_categorical(all_waves_y, num_classes = len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_x_train, all_waves_x_test, all_waves_y_train, all_waves_y_test = train_test_split(\n",
    "    np.array(all_waves_df['tensor_with_padding'].values),\n",
    "    np.array(all_waves_y),\n",
    "    test_size = 0.2,\n",
    "    random_state = 777,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [00:00<00:00, 41947.38it/s]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in tqdm(np.array(all_waves_df['tensor_with_padding'].values)):\n",
    "    l.append(convert_to_tensor(i.reshape(1,len(i))))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 21,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [],
   "source": [
    "all_waves_x_train, all_waves_x_test, all_waves_y_train, all_waves_y_test = train_test_split(\n",
    "    l,\n",
    "    np.array(all_waves_y),\n",
    "    test_size = 0.2,\n",
    "    random_state = 777,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
=======
   "execution_count": 22,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 385/385 [00:06<00:00, 59.75it/s] \n"
=======
      "2022-12-06 16:44:59.568750: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 400475520 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.664753: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 401921280 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.760527: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 403367040 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.862497: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 404812800 exceeds 10% of free system memory.\n",
      "2022-12-06 16:44:59.956855: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 406258560 exceeds 10% of free system memory.\n"
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
     ]
    }
   ],
   "source": [
    "t = all_waves_x_train[0]\n",
    "for i in tqdm(all_waves_x_train[1:]):\n",
    "    t = Concatenate(axis=0)([t,i])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 60,
=======
   "execution_count": 23,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 194.36it/s]\n"
     ]
    }
   ],
   "source": [
    "ttest = all_waves_x_test[0]\n",
    "for i in tqdm(all_waves_x_test[1:]):\n",
    "    ttest = Concatenate(axis=0)([ttest,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixou rodou por 15min e não printou nada..."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
=======
   "execution_count": 24,
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
<<<<<<< HEAD
      "13/13 [==============================] - ETA: 0s - loss: 6.0379 - accuracy: 0.0026  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1020s 79s/step - loss: 6.0379 - accuracy: 0.0026 - val_loss: 6.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 5.7364 - accuracy: 0.0104  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1079s 82s/step - loss: 5.7364 - accuracy: 0.0104 - val_loss: 6.3460 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 5.4372 - accuracy: 0.0052  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1079s 83s/step - loss: 5.4372 - accuracy: 0.0052 - val_loss: 6.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 5.1589 - accuracy: 0.0104  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1118s 86s/step - loss: 5.1589 - accuracy: 0.0104 - val_loss: 6.6705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.9046 - accuracy: 0.0155  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1098s 84s/step - loss: 4.9046 - accuracy: 0.0155 - val_loss: 6.9279 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.7662 - accuracy: 0.0155  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1120s 86s/step - loss: 4.7662 - accuracy: 0.0155 - val_loss: 7.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.5512 - accuracy: 0.0207  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1125s 86s/step - loss: 4.5512 - accuracy: 0.0207 - val_loss: 7.3723 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.3833 - accuracy: 0.0233  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1138s 87s/step - loss: 4.3833 - accuracy: 0.0233 - val_loss: 7.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.1929 - accuracy: 0.0389  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1176s 90s/step - loss: 4.1929 - accuracy: 0.0389 - val_loss: 7.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 4.0896 - accuracy: 0.0440  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1222s 93s/step - loss: 4.0896 - accuracy: 0.0440 - val_loss: 8.0330 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 3.8781 - accuracy: 0.0570  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "13/13 [==============================] - 1365s 103s/step - loss: 3.8781 - accuracy: 0.0570 - val_loss: 8.2937 - val_accuracy: 0.0000e+00\n",
      "Epoch 11: early stopping\n"
=======
      " 1/76 [..............................] - ETA: 5:14:13 - loss: 8.0126 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/claudio/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
     ]
    }
   ],
   "source": [
    "hist = all_waves_model.fit(\n",
    "    x = t, \n",
    "    y = np.asarray(all_waves_y_train).astype('float32'),\n",
    "    epochs = 100, \n",
    "    callbacks = [early_stop, checkpoint], \n",
    "    batch_size = 32, \n",
    "    validation_data = (ttest, all_waves_y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label = 'train')\n",
    "plt.plot(hist.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.model.save_weights(\"./model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.13"
=======
   "version": "3.9.2"
>>>>>>> 64d49fef51ca10294da75408561da66f2c892e7a
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aea149784bd30735ce6bf75b9a5314843328adf2083b944f20623ef50c2ca00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
